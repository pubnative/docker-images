spark.master k8s://https://kubernetes.default:443
spark.kubernetes.namespace jupyterhub
spark.kubernetes.container.image <spark-executor-image>
spark.submit.deployMode client
spark.files /home/jovyan/shared/credentials/ds-credentials.json
spark.executorEnv.GOOGLE_APPLICATION_CREDENTIALS ds-credentials.json
spark.kubernetes.pyspark.pythonVersion 3
spark.jars /usr/local/spark/jars/gcs-connector-hadoop3-2.2.4-shaded.jar
spark.jars.packages org.apache.spark:spark-hadoop-cloud_2.12:3.2.0
spark.hadoop.fs.s3a.impl org.apache.hadoop.fs.s3a.S3AFileSystem
spark.hadoop.fs.s3a.fast.upload true
spark.hadoop.fs.gs.impl com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem
spark.hadoop.fs.AbstractFileSystem.gs.impl com.google.cloud.hadoop.fs.gcs.GoogleHadoopFS
spark.driver.extraJavaOptions -Dio.netty.tryReflectionSetAccessible=true
spark.executor.extraJavaOptions -Dio.netty.tryReflectionSetAccessible=true
spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version 2
spark.hadoop.mapreduce.fileoutputcommitter.cleanup-failures.ignored true
spark.hadoop.parquet.enable.summary-metadata false
spark.sql.parquet.mergeSchema false
spark.sql.parquet.filterPushdown true
spark.sql.hive.metastorePartitionPruning true
spark.hadoop.fs.s3a.committer.name file
spark.sql.sources.commitProtocolClass org.apache.spark.internal.io.cloud.PathOutputCommitProtocol
spark.sql.parquet.output.committer.class org.apache.spark.internal.io.cloud.BindingParquetOutputCommitter
